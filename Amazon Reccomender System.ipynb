{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "import gzip\n",
    "from collections import defaultdict\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readGz(f):\n",
    "    for l in gzip.open(f):\n",
    "        yield eval(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Mean Squared Error: 0.6527804770760693\n",
      "Validation Mean Squared Error: 1.4976080782955097\n"
     ]
    }
   ],
   "source": [
    "#baselines.py\n",
    "\n",
    "training_Ratings = []\n",
    "training_userRatings = defaultdict(list)\n",
    "\n",
    "\n",
    "validation_userRatings = defaultdict(list)\n",
    "\n",
    "num_lines = 0\n",
    "\n",
    "for l in readGz(\"train.json.gz\"):\n",
    "    user,business = l['reviewerID'],l['itemID']\n",
    "\n",
    "    if num_lines < 100000:\n",
    "        training_Ratings.append(l['rating'])\n",
    "        training_userRatings[user].append(l['rating'])\n",
    "        num_lines +=1\n",
    "    else:\n",
    "        validation_userRatings[user].append(l['rating'])\n",
    "        \n",
    "globalAverage = sum(training_Ratings) / len(training_Ratings)\n",
    "userAverage = {}\n",
    "for u in training_userRatings:\n",
    "    userAverage[u] = sum(training_userRatings[u]) / len(training_userRatings[u])\n",
    "\n",
    "#find rating mse for training and validation data\n",
    "training_mse = 0\n",
    "validation_mse = 0\n",
    "num_lines2 = 0\n",
    "for l in readGz(\"train.json.gz\"):\n",
    "    user,business = l['reviewerID'],l['itemID']\n",
    "    if user in userAverage:\n",
    "        prediction = userAverage[user]\n",
    "    else:\n",
    "        prediction = globalAverage\n",
    "    if num_lines2 < 100000:\n",
    "        training_mse += (l['rating'] - prediction)**2\n",
    "    if num_lines2 >= 100000:\n",
    "        validation_mse += (l['rating'] - prediction)**2\n",
    "    num_lines2 +=1\n",
    "\n",
    "print(\"Training Mean Squared Error: \" + str(training_mse/100000))\n",
    "print(\"Validation Mean Squared Error: \" + str(validation_mse/100000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create training and validation set\n",
    "training_data = {}\n",
    "validation_data = {}\n",
    " \n",
    "all_users = list()\n",
    "all_items= list()\n",
    "    \n",
    "split=0\n",
    "#create training and validation set\n",
    "for l in readGz(\"train.json.gz\"):\n",
    "    user,item,rating = l['reviewerID'],l['itemID'],l['rating']\n",
    "    all_users.append(user)\n",
    "    all_items.append(item)\n",
    "    \n",
    "    if split < 100000:\n",
    "        training_data[(user,item)] = rating\n",
    "    else:\n",
    "        validation_data[(user,item)] = rating\n",
    "    split += 1    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#baseline gets 1.31393 on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin gradient descent\n",
      "iteration number 0\n",
      "Current MSE: 12.4667939721232\n",
      "iteration number 1000\n",
      "Current MSE: 0.08309732063210085\n",
      "iteration number 2000\n",
      "Current MSE: 2.6389477891762247\n",
      "iteration number 3000\n",
      "Current MSE: 0.26272260115903334\n",
      "iteration number 4000\n",
      "Current MSE: 0.005670757470407415\n",
      "iteration number 5000\n",
      "Current MSE: 0.7285970601789586\n",
      "iteration number 6000\n",
      "Current MSE: 0.12207133629252477\n",
      "iteration number 7000\n",
      "Current MSE: 2.454080578037954\n",
      "iteration number 8000\n",
      "Current MSE: 0.24522323442906374\n",
      "iteration number 9000\n",
      "Current MSE: 1.522946728517134\n"
     ]
    }
   ],
   "source": [
    "#latent factor model\n",
    "import random\n",
    "#perform grad descent\n",
    "n=5\n",
    "P= np.random.rand(len(all_users),n)\n",
    "Q= np.random.rand(n, len(all_items))\n",
    "alpha = globalAverage\n",
    "beta_u = np.random.rand(len(all_users),1)\n",
    "beta_i = np.random.rand(len(all_items), 1)\n",
    "index=0\n",
    "lmbda = .05 #lambda hyperparam\n",
    "gamma= .01 #gamma hyperparam\n",
    "iterations = 10000\n",
    "#try batch grad descent,or  try increasing learning rate and adding regularization terms\n",
    "\n",
    "print(\"begin gradient descent\")\n",
    "for i in range(iterations):\n",
    "    if i %1000 ==0:\n",
    "        print(\"iteration number \" + str(i) )\n",
    "        gamma = gamma*.1\n",
    "   # print(\"iteration number \" + str(i))\n",
    "\n",
    "    pair = random.choice(list(training_data.keys()))\n",
    "    r_ui = training_data[pair]\n",
    "    (userId,itemId) = pair    \n",
    "    uIndex = all_users.index(userId)    \n",
    "    iIndex = all_items.index(itemId)\n",
    "    summation = 0\n",
    "    q_val = np.zeros((n, len(all_items))) #innefiicient to make 2 different 2 matricies each loop, more effiecent to \n",
    "    p_val = np.zeros((len(all_users),n))\n",
    "    for j in range(n):\n",
    "        summation += np.dot(P[uIndex][j],Q[j][iIndex])\n",
    "        q_val += Q[j][iIndex]\n",
    "        p_val += P[uIndex][j]\n",
    "    grad_a = 2*(r_ui -(alpha + beta_u[uIndex] +beta_i[iIndex] + summation))*-1 \n",
    "    grad_bu = 2*(r_ui -(alpha + beta_u[uIndex]+beta_i[iIndex] + summation))*-1\n",
    "    grad_bi = 2*(r_ui -(alpha + beta_u[uIndex]+beta_i[iIndex] + summation))*-1\n",
    "    grad_p = 2*(r_ui -(alpha + beta_u[uIndex]+beta_i[iIndex] + summation))*-q_val.T + lmbda*2*p_val\n",
    "    grad_q = 2*(r_ui -(alpha + beta_u[uIndex]+beta_i[iIndex] + summation))*-p_val.T + lmbda*2*q_val\n",
    "\n",
    "    \n",
    "    alpha = alpha - gamma*grad_a\n",
    "    beta_u[uIndex] = beta_u[uIndex] - gamma*grad_bu #change to only update relevent element of beta vector\n",
    "    beta_i[iIndex] = beta_i[iIndex] - gamma*grad_bi\n",
    "    P = P - gamma*grad_p\n",
    "    Q = Q - gamma*grad_q\n",
    "    if i %1000 ==0:\n",
    "        real_rating = training_data[pair]\n",
    "        pred_rating = alpha[0] + beta_u[uIndex][0] + beta_i[iIndex][0] + np.dot(P[uIndex],(Q.T)[iIndex]) + lmbda*(np.dot(P[userindex],P[userindex])+np.dot((Q.T)[itemindex],(Q.T)[itemindex])) \n",
    "        mse = (real_rating - pred_rating)**2\n",
    "        print(\"Current MSE: \" + str(mse))\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin calculating training mean squared error\n",
      "Training Data mse: 1.4589487400993177\n",
      "begin calculating validation mean squared error\n",
      "Validation mse: 1.4404220129871395\n"
     ]
    }
   ],
   "source": [
    "\n",
    "training_mse = 0\n",
    "print(\"begin calculating training mean squared error\")\n",
    "for pair in training_data.keys():\n",
    "    real_rating = training_data[pair]\n",
    "    (userId,itemId) = pair\n",
    "    userindex = all_users.index(userId)\n",
    "    itemindex = all_items.index(itemId)\n",
    "#     print(beta_u.shape)\n",
    "#     print(P[userindex].shape)\n",
    "#     print((Q.T)[itemindex].shape)\n",
    "#     print(np.dot(P[userindex][:],Q[:][itemindex]).shape)\n",
    "    pred_rating = alpha[0] + beta_u[userindex][0] +beta_i[itemindex][0] + np.dot(P[userindex],(Q.T)[itemindex]) + lmbda*(np.dot(P[userindex],P[userindex])+np.dot((Q.T)[itemindex],(Q.T)[itemindex])) \n",
    "    #continuously print mse to ensure it is decreasing\n",
    "    training_mse += (real_rating- pred_rating)**2\n",
    "print(\"Training Data mse: \"+ str(training_mse/len(training_data.keys())))\n",
    "\n",
    "print(\"begin calculating validation mean squared error\")\n",
    "\n",
    "validation_mse = 0\n",
    "for pair in validation_data.keys():\n",
    "    real_rating = validation_data[pair]\n",
    "    (userId,itemId) = pair\n",
    "    userindex = all_users.index(userId)\n",
    "    itemindex = all_items.index(itemId)\n",
    "    pred_rating = alpha[0] + beta_u[userindex][0]+ beta_i[itemindex][0] + np.dot(P[userindex],(Q.T)[itemindex]) + lmbda*(np.dot(P[userindex],P[userindex])+np.dot((Q.T)[itemindex],(Q.T)[itemindex])) \n",
    "    #continuously print mse to ensure it is decreasing\n",
    "    validation_mse += (real_rating - pred_rating)**2\n",
    "print(\"Validation mse: \"+ str(validation_mse/len(validation_data.keys())))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline\n",
    "Training Mean Squared Error: 0.6527804770760693\n",
    "Validation Mean Squared Error: 1.4976080782955097\n",
    "\n",
    "My Results\n",
    "lambda: .01, gamma .001, iters: 10000, 5 factors\n",
    "Training Data mse: 1.3465521145092358\n",
    "begin calculating validation mean squared error\n",
    "Validation mse: 1.3399293960615437\n",
    "\n",
    "lambda: .01 gamma .005 iters 10000, 5 factors\n",
    "Training Data mse: 1.3465207720142207\n",
    "begin calculating validation mean squared error\n",
    "Validation mse: 1.3398456298426356\n",
    "\n",
    "\n",
    "lambda: .01 gamma .01 iters 10000, 5 factors\n",
    "Training Data mse: 1.386371888971709\n",
    "begin calculating validation mean squared error\n",
    "Validation mse: 1.3775317550803412\n",
    "\n",
    "\n",
    "lambda: .01 gamma .005 iters 10000, 10 factors\n",
    "Training Data mse: 1.422641247989086\n",
    "begin calculating validation mean squared error\n",
    "Validation mse: 1.4126002616984492\n",
    "\n",
    "lambda: .01 gamma .005 iters 10000, 3 factors\n",
    "Training Data mse: 1.3488242622374744\n",
    "begin calculating validation mean squared error\n",
    "Validation mse: 1.3446991268837358\n",
    "\n",
    "same as above with 6 latent factors\n",
    "Training Data mse: 1.3602101491616267\n",
    "begin calculating validation mean squared error\n",
    "Validation mse: 1.3520673845715372\n",
    "\n",
    "\n",
    "lambda: .05 gamma .005 iters 10000, 5 factors\n",
    "Training Data mse: 1.3626210835902632\n",
    "begin calculating validation mean squared error\n",
    "Validation mse: 1.3529848505500985\n",
    "\n",
    "\n",
    "begin calculating training mean squared error\n",
    "Training Data mse: 1.4172102100973825\n",
    "begin calculating validation mean squared error\n",
    "Validation mse: 1.4152499820427742"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
